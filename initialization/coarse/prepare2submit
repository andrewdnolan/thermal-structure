#!/usr/bin/env bash

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# prepare2submit.sh
#   - create neccesary files and job submission scripts for uncoupled init
#     of our input geometries.
#
#   Note:
#     - This script does not work correctly on OSX!!!!
#       Must be run from linux machine!!!!
#       getopt (which support long opts) only works on linux
#
#     - Files and submission scipts are group by geometry size classification
#       since runtime and memory usage should be similar amougnst geometries of
#       the same size. This flawed, but straight forward approach means the mem.
#       and runtime allocation in each `submit` script is dictated by the largest
#       geometry in each group.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

check_vars_defined()
{
  local not_set=false
  for var in $2; do
    if [ -z ${!var} ]; then
      echo
      echo "Error:"
      echo "    ${var} is NOT set"
      local not_set=true
    fi
  done

  if [ $not_set = true ]; then
    echo
    echo "********************************************************************"
    echo "function: ${1} can not be run, not all necessary vars are set."
    echo "********************************************************************"
    echo
    exit 1
  fi
}

parse_prepare_args()
{ #https://gist.github.com/cosimo/3760587
  #https://www.aplawrence.com/Unix/getopts.html
  #https://stackoverflow.com/a/7948533/10221482
  #https://www.bahmanm.com/2015/01/command-line-options-parse-with-getopt.html

  OPTS=`getopt -o fhm:t:g:s: --long force,help,mem:,time:,group:,stride:, -n 'parse-options' -- "$@"`

  if [ $? != 0 ] ; then echo "Failed parsing options." >&2 ; exit 1 ; fi

  usage="
  $(basename "$0") [-h] [--dx dx --dt dt --tt tt --key key --fit fit  --off off --sif sif ]
  --
  program to generate SLURM job array submission scripts for a given size class

  where:
      -h | --help  ) show this help text
      -f | --force ) overwrite .in/.out files if they already exist
      -m | --mem   ) Memory request for one job in the SLURM job array. Default
                      units are MB.
      -t | --time  ) Wall time request for one job in the SLURM job array.
                    Must be in: HH:MM:SS format
      -g | --group ) Glacier size class [small, medium, large] to prepare
      -s | --stride) How many jobs in the SLURM array to submit at once default=10
      "

  # Set deaults options
  HELP=false
  FORCE=false
  JS=10

  eval set -- "$OPTS"
  while true; do
    case "$1" in
      -f | --force ) FORCE=true; shift ;;
      -h | --help  ) echo "$usage"; exit 0 ;;
      -m | --mem   ) MEM="$2"; shift 2 ;;
      -t | --time  ) RUN_TIME="$2"; shift 2;;
      -g | --group ) size="$2"; shift 2;;
      -s | --stride) JS="$2"; shift 2;;
      -- ) shift; break ;;
      * ) break ;;
    esac
  done

  # check the size is passed correctly
  local ok_size=false
  for s in "small" "medium" "large"; do
    if [ $s = $size ]; then
      local ok_size=true
    fi
  done

  if [ $ok_size = false ];then
    echo
    echo "**********************************************************************"
    echo "Error: Incorrect size passed to -g. Select from [small, medium, large]"
    echo "**********************************************************************"
    echo
    exit 1
  fi

  # Check the time is passed correctly
  if grep -qv -P '\d*:\d\d:\d\d' <<<"$RUN_TIME"; then
    echo
    echo "**********************************************************************"
    echo "Error: RUN_TIME not in correct format (hh:mm:ss)."
    echo "**********************************************************************"
    echo
    exit 1
  fi
}

parse_make_sif_args()
{ #https://gist.github.com/cosimo/3760587
  #https://www.aplawrence.com/Unix/getopts.html
  #https://stackoverflow.com/a/7948533/10221482
  #https://www.bahmanm.com/2015/01/command-line-options-parse-with-getopt.html

  OPTS=`getopt -o hx:t:T:k:f:p:o:s: --long help,dx:,dt:,tt:,key:,fit:,ord:,off:,sif:, -n 'parse-options' -- "$@"`

  if [ $? != 0 ] ; then echo "Failed parsing options." >&2 ; exit 1 ; fi

  usage="
  $(basename "$0") make_sif [-h] [--dx dx --dt dt --tt tt --key key --fit fit --ord ord --off off --sif sif ]
  --
  program to create exectuable .sif file from template based of params passed

  where:
      -h | --help ) show this help text
      -x | --dx   ) mesh resolution                         [m]
      -t | --dt   ) time step                               [y]
      -T | --tt   ) length of the simulation                [y]
      -k | --key  ) glacier id key
      -f | --fit  ) fit type to Young et al 2020. MB data
      -p | --ord  ) Order of spline used to prescribe MB
      -o | --off  ) offset to mass balance curve            [m i.e.q yr^-1]
      -s | --sif  ) path to template sif file

      "
  # set default arg for those that need one
  local HELP=false

  eval set -- "$OPTS"
  while true; do
    case "$1" in
      -h | --help ) echo "$usage";exit 0;;
      -x | --dx   ) dx="$2";     shift 2;;
      -t | --dt   ) dt="$2";     shift 2;;
      -T | --tt   ) TT="$2";     shift 2;;
      -k | --key  ) KEY="$2";    shift 2;;
      -f | --fit  ) FIT="$2";    shift 2;;
      -p | --ord  ) k="$2";      shift 2;;
      -o | --off  ) OFFSET="$2"; shift 2;;
      -s | --sif  ) SIF="$2";    shift 2;;
      -- ) shift; break ;;
      * ) break ;;
    esac
  done

  SIF=$(sed -e 's/^"//' -e 's/"$//' <<<"$SIF")
  OFFSET=$(sed -e 's/^"//' -e 's/"$//' <<<"$OFFSET")

  check_vars_defined "make_sif" "dx dt TT KEY FIT OFFSET SIF k"
}

parse_json()
{
  #-----------------------------------------------------------------------------
  # Parse model parameters from input .json file needed for initialization
  # perl code from: https://stackoverflow.com/a/27127626/10221482
  #-----------------------------------------------------------------------------
  # $1 (json_fp) --->   file path to json parameter file
  #-----------------------------------------------------------------------------

  # parse MB grid search start
  MB_0=$( perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{MB}->{range}->[0]
    ' $1 )
  # parse MB grid search stride
  MB_s=$( perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{MB}->{range}->[1]
    ' $1 )
  # parse MB grid search end
  MB_f=$( perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{MB}->{range}->[2]
    ' $1 )
  # parse horizontal gird spacing
  dx=$(   perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{dx}
    ' $1 )
  # parse time step size
  dt=$(   perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{dt}
    ' $1 )
  # parse MB curve fit type
  TT=$(   perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{TT}
    ' $1 )
  # parse MB curve fit type
  FIT=$(   perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{fit}
    ' $1 )
  # parse MB curve fit type
  k=$(   perl -MJSON -0lnE '
    $params = decode_json $_;
    say $params->{k}
    ' $1 )
}

make_RUN_name()
{
  #-----------------------------------------------------------------------------
  # Make the `RUN` named based on the required parameters passed
  # ----------------------------------------------------------------------------
  # $KEY       --->   glacier id key
  # $TT        --->   length of the simulation                [y]
  # $dt        --->   time step                               [y]
  # $dx        --->   mesh resolution                         [m]
  # $OFFSET    --->   offset to mass balance curve            [m i.e.q yr^-1]
  # $FIT       --->   fit type to Young et al 2020. MB data
  #-----------------------------------------------------------------------------

  check_vars_defined "make_RUN_name" "KEY TT dt dx OFFSET FIT k"

  local RUN="${KEY}_${TT}a_dt_${dt}_dx_${dx}_MB_${OFFSET}_OFF_${FIT}_k${k}"
  echo $RUN
}

make_sif()
{
  #-----------------------------------------------------------------------------
  # Pass parameters to be replaced in sif template. Function calll results in an
  # `.sif` file that can be run by `ElmerSolver`.
  #
  # This function can be called internally, but the `check_args` function has
  # been written so that it can be called directly from the command line.
  #
  # ----------------------------------------------------------------------------
  # $dx       --->   mesh resolution                         [m]
  # $dt       --->   time step                               [y]
  # $TT       --->   length of the simulation                [y]
  # $KEY      --->   glacier id key
  # $FIT      --->   fit type to Young et al 2020. MB data
  # $OFFSET   --->   offset to mass balance curve            [m i.e.q yr^-1]
  # $SIF      --->   path to template sif file
  #-----------------------------------------------------------------------------

  check_vars_defined "make_sif" "dx dt TT KEY FIT OFFSET SIF k"


  # File paths to input topography data
  local Zb_fp="../../input_data/topography/${KEY}_bed.dat"
  local Zs_fp="../../input_data/topography/${KEY}_surf.dat"

  # Given the passed parametes make the `RUN` name variable
  local RUN=$( make_RUN_name $KEY $TT $dt $dx $OFFSET $FIT $k)
  # Calculate total number of time steps (NT) from dt and TT
  local NT=$( awk -v TT=$3 -v dt=$2 "BEGIN { print TT/dt }" )

  # Update the .SIF FILE with the model run specifc params
  sed "s#<DX>#"$dx"#g;
       s#<dt>#"$dt"#g;
       s#<NT>#"$NT"#g;
       s#<RUN>#"$RUN"#g;
       s#<KEY>#"$KEY"#g;
       s#<FIT>#"$FIT"#g;
       s#<Zs_fp>#"$Zs_fp"#g;
       s#<Zb_fp>#"$Zb_fp"#g;
       s#<OFFSET>#"$OFFSET"#g" "$SIF" > "./sifs/${RUN}.sif"

  echo "./sifs/${RUN}.sif"
}

check_inout_files()
{
  check_vars_defined "check_inout_files" "group FORCE"

  for ext in "in" "out"; do

    # check if file already exists
    if [ -f "./run/${group}.${ext}" ] && [ $FORCE = false ]; then
      echo
      echo "********************************************************************"
      echo -e "Input file: \"./run/${group}.${ext}\" already exists.\n"\
      "  Either manually remove the \"./run/${group}.${ext}\" file or\n"\
      "  run this script with the \" -FORCE \" flag to overwrite files."
      echo "********************************************************************"
      echo
      exit 1

    # if file exists but force flag passed, delete it
    elif [ -f "./run/${group}.${ext}" ] && [ $FORCE = true ]; then
      # remove the existing file
      rm -f "./run/${group}.${ext}"
    fi

  done
}

make_input_file()
{
  #-----------------------------------------------------------------------------
  # $MB_0  --->   start  of MB gridsearch                 [m i.e.q yr^-1]
  # $MB_f  --->   end    of MB gridsearch                 [m i.e.q yr^-1]
  # $MB_s  --->   stride of MB gridsearch                 [m i.e.q yr^-1]
  # $dx    --->   mesh resolution                         [m]
  # $TT    --->   length of the simulation                [y]
  # $dt    --->   time step                               [y]
  # $KEY   --->   glacier id key
  # $FIT   --->   fit type to Young et al 2020. MB data
  #-----------------------------------------------------------------------------

  check_vars_defined "make_input_file" "MB_0 MB_f MB_s dx TT dt KEY FIT k"

  for OFFSET in $(seq -w $MB_0 $MB_s $MB_f);do
    echo "make_sif --dx ${dx} --dt ${dt} --tt ${TT} --key ${KEY} --fit ${FIT}"\
         " --ord ${k} --off \"${OFFSET}\" --sif \"./sifs/simple_spinup.sif\" " \
         >> "./run/${group}.in"
  done

}

make_output_file()
{
  #-----------------------------------------------------------------------------
  # $MB_0  --->   start  of MB gridsearch                 [m i.e.q yr^-1]
  # $MB_f  --->   end    of MB gridsearch                 [m i.e.q yr^-1]
  # $MB_s  --->   stride of MB gridsearch                 [m i.e.q yr^-1]
  # $KEY   --->   glacier id key
  # $TT    --->   length of the simulation                [y]
  # $dt    --->   time step                               [y]
  # $dx    --->   mesh resolution                         [m]
  # $FIT   --->   fit type to Young et al 2020. MB data
  #-----------------------------------------------------------------------------

  check_vars_defined "make_output_file" "MB_0 MB_f MB_s KEY TT dt dx FIT k"

  # Calculate total number of time steps (NT) from dt and TT
  local NT=$( awk -v TT=$TT -v dt=$dt "BEGIN { print TT/dt }" )

  for OFFSET in $(seq -w $MB_0 $MB_s $MB_f);do

    # Given the passed parametes and the current offset make `RUN` name variable
    local RUN=$( make_RUN_name $KEY $TT $dt $dx $OFFSET $FIT $k)

    echo  ../../src/elmer2nc/elmer2nc.sh  -r "./result/${KEY}/mesh_dx${dx}/${RUN}.result" \
                                          -m "./result/${KEY}/mesh_dx${dx}/" \
                                          -t $NT \
                                          -o "./result/${KEY}/nc/" \
                                          >> "./run/${group}.out"
  done
}

check_njobs()
{
  check_vars_defined "check_njobs" "group "

  local n_in=$(cat "./run/${group}.in" | wc -l)
  local n_out=$(cat "./run/${group}.out" | wc -l )

  if [ $n_in -ne $n_out ]; then
    echo
    echo "********************************************************************"
    echo -e "Input and Ouput files are different lenghts for group \" ${group} \"."
    echo "********************************************************************"
    echo
    exit 1
  else
    njobs=$n_in
  fi

}

make_group_name()
{
  check_vars_defined "make_group_name" "group "

  local group_name="${group}_spline_init"

  echo $group_name
}

make_submit_scipt()
{

  check_vars_defined "check_vars_defined" "njobs JS MEM RUN_TIME JOB_NAME group"


  # For formating to work correctly, this variable has to be printed within quotes
  template=$(cat << EOF
#!/bin/bash
#SBATCH --array=1-<NJ>%<JS>                  # <NJ> jobs that run <JS> at a time
#SBATCH --job-name=<JOB_NAME>           # base job name for the array
#SBATCH --mem-per-cpu=<MEM>                     # maximum <MEM>MB per job
#SBATCH --time=<RUN_TIME>                      # maximum walltime per job
#SBATCH --nodes=1                                  # Only one node is needed
#SBATCH --ntasks=1                                 # These are serial jobs
#SBATCH --mail-type=ALL                            # send all mail (way to much)
#SBATCH --mail-user=andrew.d.nolan@maine.edu       # email to spend updates too
#SBATCH --output=logs/<JOB_NAME>_%A_%a.out  # standard output
#SBATCH --error=logs/<JOB_NAME>_%A_%a.err   # standard error
# in the previous two lines %A" is replaced by jobID and "%a" with the array index

#Load cedar module file
source ../../config/modulefile.cc.cedar

# Get the command to create run specific .sif file
CREATE=\$( sed -n "\${SLURM_ARRAY_TASK_ID}p" <in_fp> )

# create the .sif file, filename is 'returend' (kinda) by the function
SIF=\$(./prepare2submit \$CREATE)

# Get the command to convert from .result to NetCDF
CONVERT=\$( sed -n "\${SLURM_ARRAY_TASK_ID}p" <out_fp> )

# Start the timer
start=\$(date +%s.%N)

# Execute the .sif file
ElmerSolver \$SIF

# End the timer
end=\$(date +%s.%N)

# Execution time of the solver
runtime=\$(awk -v start=\$start -v end=\$end 'BEGIN {print end - start}')

# Log the execution time
../../src/utils/elmer_log.sh \$CREATE --ET \$runtime

# Do post-processing file conversion
\$CONVERT

# remove the sif
rm -f \$SIF
EOF
  )

  # write the template submit script to a temp file
  echo "$template" > "./run/tmp.sh"

  # intermidate variables: in and out command files
  IN_fp="./run/${group}.in"
  OUT_fp="./run/${group}.out"

  sed "s#<NJ>#"$njobs"#g;
       s#<JS>#"$JS"#g;
       s#<MEM>#"$MEM"#g;
       s#<in_fp>#"$IN_fp"#g;
       s#<out_fp>#"$OUT_fp"#g;
       s#<RUN_TIME>#"$RUN_TIME"#g;
       s#<JOB_NAME>#"$JOB_NAME"#g;" "./run/tmp.sh" > "./run/${JOB_NAME}.sh"

  # remove the temp template
  rm -f "./run/tmp.sh"

  chmod +x "./run/${JOB_NAME}.sh"
}

prepare2submit()
{
  check_vars_defined "prepare2submit" "size FORCE MEM RUN_TIME"

  #https://stackoverflow.com/a/16461878/10221482
  #complicated b/c you can't pass an array to a bash function
  local group="${size}"
  local arr_name="${size}[@]"
  local group_arr=("${!arr_name}")

  # check whether in/out files exist
  check_inout_files $group $FORCE

  # loop over elements of the group
  for KEY in "${group_arr[@]}"; do
    # extract parameter values from the json file
    parse_json "./params/${KEY}.json"

    # Add the `.sif` creation command to the input .txt file
    make_input_file $MB_0 $MB_s $MB_f $dx $TT $dt $KEY $k

    # Add the  NetCDF creation command to the output .txt file
    make_output_file $MB_0 $MB_s $MB_f $KEY $TT $dt $dx $FIT $k
  done

  # Needs to find number of jobs per group
  check_njobs $group

  # Make group specific run name
  JOB_NAME=$(make_group_name $group)

  # Make job submission script
  make_submit_scipt $njobs $JS $RUN_TIME $MEM $JOB_NAME $group

}

################################################################################
# FORCE=true
# MEM=100
# RUN_TIME="1:15:00"
# JS=10

main(){
  # Declare arrays for the individual size classifications
  declare -a  small=("crmpt12" "crmpt18-a" "crmpt18-b" "glc1-a" "glc1-b")
  declare -a medium=("lilk-a" "lilk-b" "klun-a" "klun-b" "sprg")
  declare -a  large=("twds-b" "fish" "klut-a" "klut-b")
  # Declare a nested arrays containing the sub-arrays
  # declare -a groups=("small" "medium" "large")


  local run_make_sif=false

  # Check if we are running one of our special functions from the command line
  case $1 in
    # make the individual sif file
    'make_sif') run_make_sif=true; shift ;;
  esac

  if [ $run_make_sif = true ]; then
    parse_make_sif_args "$@"

    # If all the check are passed, finally actually call the function
    make_sif $dx $dt $TT $KEY $FIT $OFFSET $SIF
  else
    parse_prepare_args "$@"

    prepare2submit $size $FORCE $MEM $RUN_TIME
  fi

}

#run the whole thing.
main "$@"
